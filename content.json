{"meta":{"title":"WY's blog","subtitle":null,"description":null,"author":"WangY","url":"the-valley.github.io","root":"/"},"pages":[],"posts":[{"title":"工作中遇到的SQL优化总结","slug":"工作中遇到的SQL优化总结","date":"2019-12-29T13:13:14.000Z","updated":"2019-12-29T13:14:29.076Z","comments":true,"path":"2019/12/29/工作中遇到的SQL优化总结/","link":"","permalink":"the-valley.github.io/2019/12/29/工作中遇到的SQL优化总结/","excerpt":"","text":"工作中遇到的SQL优化总结多表join优化场景前两天线上更新了一个版本，上线后接口影响很慢，对于一些数量比较多的条目就直接超时了（超过了50秒）。因为业务场景偏OLAP且数据量很大，所以程序中自定义了mybatis的拦截器，在日志中记录了执行的SQL语句与其执行时间。所以定位到了此接口中的主要查询语句执行了50S，下面开始分析问题。 表信息与这条SQL相关的表总共有四张。 查询语句结构大致如下： 1234567SELECT colsFROM main_table mtJOIN slave_table1 st1 ON mt.col1 = st1.col2LEFT JOIN slave_table2 st2 ON mt.col3 = st1.col4 AND st1.col5 = st2.col6LEFT JOIN slave_table3 st3 ON mt.col1 = collate utf8mb4_generic_ci st3.col2 and clause...where clause...GROUP BY mt.col1 各个表的数据量如下： 表名 数据量 main_table 200W slave_table1 2000W slave_table2 4000 slave_table3 10W 优化思路第一步分析表的执行计划，（索引全部命中，所以这里只显示了几列，并且外层的查询），table列顺序如下表： id table rows 1 Main_table 26946 2 slave_table1 8 3 slave_table2 1 4 slave_table3 1 之前对于rows列一直有一个误解，最近在高性能mysql中重新看了下explain的章节，解释如下： 重要的一句：rows这一列是说MySQL从一张表中查出来符合条件的记录需要读取的平均行数，是内嵌循环关联计划里的循环数目。 看到这里总是要思考下，这个内嵌循环关联是什么？可以看一下官方文档。文档中说明了其算法逻辑： 哈哈，简单粗暴，循环就对了。了解了这些开始对之前的SQL进行优化，猜想：left join的顺序会不会对查询时间有影响。现在对join顺序进行调整，把slave_table1放在最后面。 id table rows 1 Main_table 26946 2 slave_table2 1 3 slave_table3 1 4 slave_table1 8 执行时间：30s。快了将近一倍。 进行分析：从内嵌循环关联算法逻辑出发，推导原因。 对于最初的顺序：当主表查询出来有200W条数据时，left join slave_table1时（粗略统计主表的每条记录在slave_table1有5个符合条件的记录），那这时候需要对slave_table1进行的查询次数为200W，且生成的中间表数据为200W*5 = 1000W，join slave2时（slave_table2有且只有一条符合条件的记录）这里需要对slave_table2查询1000W次，slave_table3的道理类似，也需要进行1000次。总的查询次数为 slave_table1 200W, slave_table2 1000W, slave_table3 1000W. 对于调整后的顺序：当主表查询出来有200W条数据时，left join slave_table2时，需要对slave_table2进行的查询次数为200W，且生成的中间表数据为200W*1 = 200W，join slave3时需要对slave_table3查询200W次，生成的中间表数据量为200W。最后join slave_table1，也需要200W次。总的查询次数为 slave_table1 200W, slave_table2 200W, slave_table3 200W. 第二步联合索引顺序的优化。对于联合索引，一般有一个经验性的优化法则：选择性高的列放在前面，但是这并适合的已有的场景。在《高性能MySQL》书中， 在不考虑数据分布与分组的情况下，把选择性高的列放在前面的位置，可以优化where条件的查找。但是数据查询时有明显的分组效果，这时就需要考虑调整联合索引的位置来优化查询速度，比如减少IO。 对于B+树索引，每检索一层，都会对应着一次磁盘的IO。 场景说明：在slave_table3中存在联合唯一约束（col2，col3）（这个索引的创建是根据选择性的高低来排列的）对于主表中的数据与slave3中的col3有分段分布关系的，在前面的join生成的中间表结果只可能存在唯一的col3值。此时，联合索引可以修改为（col3，col2）（即使col2列的选择性更高），这样在join查询时，mysql 可以通过读取更少的数据页，更少的磁盘IO来完成查询。 第三步字符集的优化。由于数据库之前有过一次升级，来兼容一些生僻字，把utf8编码改成了utf8mb4编码，但是在升级的过程中只修改了部分表，这就造成了字符集与collation的不统一，这样在做比较时报collation不统一的错，于是同事在sql中加入了下面的代码： 1ON mt.col1 = collate utf8mb4_generic_ci st3.col2 这句话是时间超时的最主要原因。collation的转换是一个很消耗计算资源的操作。所以在同一个数据库应该尽可能保持字符集与collation的一致性。","categories":[],"tags":[]},{"title":"","slug":"拆库web-gateway oom原因","date":"2019-11-04T10:03:48.564Z","updated":"2019-11-04T10:03:48.565Z","comments":true,"path":"2019/11/04/拆库web-gateway oom原因/","link":"","permalink":"the-valley.github.io/2019/11/04/拆库web-gateway oom原因/","excerpt":"","text":"拆库web-gateway oom原因导致原因gateway程序分配的jvm内存较小，在日志文件中打印返回信息时把整个文件流加载到了内存中，导致了堆溢出。 排查过程对jvm 堆溢出时dump出来的堆转储快照进行分析。 图片中char[]字节数组占用了562MB，这个应该是下载文件时的文件流。在日志文件打印时，需要把response body中的字节流转成字符串打印到日志文件，而这种大的char[]数组和大的字符串会直接写到jvm堆的老年代，所以会导致内存溢出。","categories":[],"tags":[]},{"title":"","slug":"Mysql分区表及自动创建分区Partition","date":"2019-10-17T11:01:56.858Z","updated":"2019-10-17T11:01:56.858Z","comments":true,"path":"2019/10/17/Mysql分区表及自动创建分区Partition/","link":"","permalink":"the-valley.github.io/2019/10/17/Mysql分区表及自动创建分区Partition/","excerpt":"","text":"#Mysql分区表及自动创建分区Partition Range分区表建表语句如下，其中分区键必须和id构成主键和唯一键 12345678910111213CREATE TABLE `test1` ( `id` char(32) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '自增主键(guid)', `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `partition_key` int(8) NOT NULL COMMENT '分区键(格式:yyyyMMdd)', PRIMARY KEY (`id`,`partition_key`), UNIQUE KEY `id_UNIQUE` (`id`,`partition_key`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ciPARTITION BY RANGE (partition_key)(PARTITION p0 VALUES LESS THAN (20180619) ENGINE = InnoDB, PARTITION p20180619 VALUES LESS THAN (20180620) ENGINE = InnoDB, PARTITION p20180621 VALUES LESS THAN (20180622) ENGINE = InnoDB, PARTITION p20180622 VALUES LESS THAN (20180623) ENGINE = InnoDB, PARTITION p20180623 VALUES LESS THAN (20180624) ENGINE = InnoDB); 新增分区 123alter TABLE `test1` add PARTITION( PARTITION p20180629 VALUES LESS THAN (20180630) ENGINE = InnoDB); 删除分区 1alter table `test1` drop PARTITION p20180629; Mysql不能自动创建分区，需要使用mysql event事件的方式自动创建分区1.创建分区的存储过程如下（每次执行先校验当前分区是否存在，如果存在则不处理；不存在则创建）： 1234567891011121314151617181920212223242526272829303132DELIMITER $$#该表所在数据库名称USE `demo`$$DROP PROCEDURE IF EXISTS `create_partition_by_day`$$CREATE PROCEDURE `create_partition_by_day`(IN_SCHEMANAME VARCHAR(64), IN_TABLENAME VARCHAR(64))BEGIN #当前日期存在的分区的个数 DECLARE ROWS_CNT INT UNSIGNED; #目前日期，为当前日期的后一天 DECLARE TARGET_DATE TIMESTAMP; #分区的名称，格式为p20180620 DECLARE PARTITIONNAME VARCHAR(9); #当前分区名称的分区值上限，即为 PARTITIONNAME + 1 DECLARE PARTITION_ADD_DAY VARCHAR(9); SET TARGET_DATE = NOW() + INTERVAL 1 DAY; SET PARTITIONNAME = DATE_FORMAT( TARGET_DATE, 'p%Y%m%d' ); SET TARGET_DATE = TARGET_DATE + INTERVAL 1 DAY; SET PARTITION_ADD_DAY = DATE_FORMAT( TARGET_DATE, '%Y%m%d' ); SELECT COUNT(*) INTO ROWS_CNT FROM information_schema.partitions WHERE table_schema = IN_SCHEMANAME AND table_name = IN_TABLENAME AND partition_name = PARTITIONNAME; IF ROWS_CNT = 0 THEN SET @SQL = CONCAT( 'ALTER TABLE `', IN_SCHEMANAME, '`.`', IN_TABLENAME, '`', ' ADD PARTITION (PARTITION ', PARTITIONNAME, \" VALUES LESS THAN (\", PARTITION_ADD_DAY ,\") ENGINE = InnoDB);\" ); PREPARE STMT FROM @SQL; EXECUTE STMT; DEALLOCATE PREPARE STMT; ELSE SELECT CONCAT(\"partition `\", PARTITIONNAME, \"` for table `\",IN_SCHEMANAME, \".\", IN_TABLENAME, \"` already exists\") AS result; END IF;END$$DELIMITER ; 2.数据库定时任务(每小时执行一次) 1234567891011121314DELIMITER $$#该表所在的数据库名称USE `demo`$$CREATE EVENT IF NOT EXISTS `daily_generate_partition`ON SCHEDULE EVERY 1 hour #执行周期，还有天、月等等STARTS '2018-06-20 00:00:00'ON COMPLETION PRESERVEENABLECOMMENT 'Creating partitions'DO BEGIN #调用刚才创建的存储过程，第一个参数是数据库名称，第二个参数是表名称 CALL datacollectcenter.create_partition_by_day('demo','test1');END$$DELIMITER ;","categories":[],"tags":[]},{"title":"","slug":"Git-Flow分支模型","date":"2019-06-22T02:53:34.554Z","updated":"2019-06-22T03:32:54.256Z","comments":true,"path":"2019/06/22/Git-Flow分支模型/","link":"","permalink":"the-valley.github.io/2019/06/22/Git-Flow分支模型/","excerpt":"","text":"Git-Flow分支模型整体图 为什么要git？有关Git与集中式源代码控制系统相比的优缺点的详细讨论，请参阅 网站。那里有很多火焰战争。作为开发人员，我更喜欢Git，而不是今天的所有其他工具。Git真的改变了开发人员对合并和分支的看法。从我来自经典的CVS / Subversion世界来看，合并/分支一直被认为有点可怕（“要小心合并冲突，它们会咬你！”）以及你每隔一段时间就会做的事情。 但是使用Git，这些操作非常便宜和简单，并且它们被认为是您日常工作流程的核心部分之一。例如，在CVS / Subversion 书籍中，分支和合并首先在后面的章节中讨论（对于高级用户），而在 每本 Git 书中，它已经在第3章（基础知识）中介绍过了。 由于其简单性和重复性，分支和合并不再是一件令人害怕的事情。版本控制工具应该比其他任何东西更有助于分支/合并。 足够的工具，让我们进入开发模型。我将在这里介绍的模型基本上只是每个团队成员必须遵循的一组程序才能进入托管软件开发过程。 分散但集中我们使用的存储库设置与该分支模型配合良好，具有中央“真实”存储库。请注意，这个仓库只 被认为 是中央仓库（因为Git是DVCS，在技术层面没有中央仓库）。我们将此repo称为origin，因为所有Git用户都熟悉此名称。 每个开发人员都会拉动并推动原点。但除了集中式推拉关系之外，每个开发人员还可以从其他同行中获取更改以形成子团队。例如，在将正在进行的工作origin过早推进之前，这对于与一个大的新功能上的两个或更多开发人员一起工作可能是有用的 。在上图中，有爱丽丝和鲍勃，爱丽丝和大卫以及克莱尔和大卫的子团队。 从技术上讲，这意味着Alice已经定义了一个Git遥控器，名为bob，指向Bob的存储库，反之亦然。 主要分支 在核心，开发模型受到现有模型的极大启发。中央仓库拥有两个主要分支，具有无限的生命周期： master develop 该master分支在origin应该熟悉到每一个用户的Git。与master分支并行，另一个分支称为develop。 我们认为origin/master是源代码HEAD总是反映生产就绪状态的主要分支 。 我们认为origin/develop是主要的分支，其源代码 HEAD始终反映了下一版本中最新交付的开发更改的状态。有些人称之为“整合分支”。这是建立任何自动夜间构建的地方。 当develop分支中的源代码到达稳定点并准备好被释放时，应该以master 某种方式将所有更改合并回来，然后使用版本号进行标记。将如何进一步详细讨论。 因此，每次将更改合并回时master，根据定义，这是一个新的生产版本。我们对此非常严格，因此从理论上讲，我们可以使用Git钩子脚本在每次提交时自动构建和推出我们的软件到我们的生产服务器 master。 支持分支接下来的主要分支master和develop，我们的发展模式，采用了多种支持分支机构，以帮助并行开发团队成员之间，缓解功能跟踪，生产准备释放，并协助快速修复现场制作的问题。与主要分支不同，这些分支的寿命有限，因为它们最终会被删除。 我们可能使用的不同类型的分支是： 功能分支 发布分支机构 修补程序分支 这些分支中的每一个都有特定的目的，并且必须遵守关于哪些分支可以是它们的起始分支以及哪些分支必须是它们的合并目标的严格规则。我们将在一分钟内完成它们。 从技术角度来看，这些分支绝不是“特殊的”。分支类型根据我们如何使用它们进行分类。他们当然是老Git分支。 功能分支 可能创建于： develop 必须合并回： develop 分支命名约定： 任何东西，除了 master，develop，release-*，或者hotfix-* 功能分支（或有时称为主题分支）用于为即将发布或将来的版本开发新功能。在开始开发特征时，此特征将在其中合并的目标版本可能在此时未知。功能分支的本质是，只要功能处于开发阶段，它就会存在，但最终会被合并回develop（以便将新功能添加到即将发布的版本中）或丢弃（在实验令人失望的情况下）。 功能分支通常仅存在于开发人员存储库中，而不存在于origin。 创建功能分支在开始处理新功能时，从develop分支分支。 12$ git checkout -b myfeature develop 切换到新分支“myfeature” 在开发中加入完成的功能完成的功能可能会合并到develop分支中，以确保将它们添加到即将发布的版本中： 12345678$ git checkout develop 切换到分支&apos;develop&apos; $ git merge --no-ff myfeature 更新ea1b82a..05e9557 （更改摘要）$ git branch -d myfeature 已删除分支myfeature（为05e9557）。$ git push origin开发 该--no-ff标志使合并始终创建新的提交对象，即使可以使用快进执行合并。这样可以避免丢失有关功能分支历史存在的信息，并将所有一起添加功能的提交组合在一起。相比： 在后一种情况下，不可能从Git历史中看到哪些提交对象一起实现了一个功能 - 您必须手动读取所有日志消息。恢复整个功能（即一组提交）在后一种情况下是一个真正的头痛，而如果使用该--no-ff标志则很容易完成 。 是的，它会创建一些（空的）提交对象，但增益远远大于成本。 发布分支 可能会创建于： develop 必须合并回： develop 和 master 分支命名约定： release-* 发布分支支持准备新的生产版本。他们允许最后一刻点缀我和交叉t。此外，它们允许修复小错误并为发布准备元数据（版本号，构建日期等）。通过在发布分支上执行所有这些工作，develop 分支将被清除以接收下一个大版本的功能。 分支新发布分支的关键时刻develop是开发（几乎）反映新版本的期望状态。至少所有针对要构建的版本的功能必须develop在此时合并到其中 。针对未来版本的所有功能可能不会 - 他们必须等到发布分支分支后。 正是在发布分支的开始，即将发布的版本被分配了一个版本号 - 而不是之前的版本号。直到那一刻，develop 分支反映了“下一个版本”的变化，但不清楚“下一个版本”最终是否会变为0.3或1.0，直到发布分支开始。该决定是在发布分支的开始时做出的，并由项目关于版本号冲突的规则执行。 创建发布分支发布分支是从develop分支创建的。例如，假设版本1.1.5是当前的生产版本，我们即将推出一个大版本。状态develop为“下一个版本”做好了准备，我们已经决定这将成为版本1.2（而不是1.1.6或2.0）。因此，我们分支并为发布分支提供反映新版本号的名称： 1234567$ git checkout -b release-1.2 develop 切换到新分支“release-1.2” $ ./bump-version.sh 1.2 文件修改成功，版本提升到1.2。$ git commit -a -m “Bumped version number to 1.2” [release-1.2 74d9424] Bumped version number改为1.2 1个文件，1个插入（+），1个删除（ - ） 在创建新分支并切换到它后，我们会修改版本号。这 bump-version.sh是一个虚构的shell脚本，它可以更改工作副本中的某些文件以反映新版本。（这当然可以是手动更改 - 关键是某些文件会发生变化。）然后，提交了有问题的版本号。 这个新的分支可能存在一段时间，直到发布可能肯定推出。在此期间，可以在此分支中应用错误修复（而不是在develop分支上）。严禁在此处添加大型新功能。它们必须合并develop，因此等待下一个大版本。 完成发布分支当发布分支的状态准备好成为真正的发布时，需要执行一些操作。首先，发布分支被合并到 master（因为每次提交master都是按照定义的新版本，请记住）。接下来，master必须标记该提交，以便将来参考此历史版本。最后，需要将发布分支上所做的更改合并回来develop，以便将来的版本也包含这些错误修复。 Git的前两个步骤： 123456$ git checkout master 切换到分支&apos;master&apos; $ git merge --no-ff release-1.2 由递归合并而成。（更改摘要）$ git tag -a 1.2 该版本现已完成，并标记以供将来参考。 编辑：您可能还想使用-s或-u &lt;key&gt;标记以加密方式对您的标记进行签名。 为了保持发布分支中所做的更改，我们需要将这些更改合并到其中develop。在Git中： 12345$ git checkout develop 切换到分支&apos;develop&apos; $ git merge --no-ff release-1.2 由递归合并而成。（变更摘要） 这一步很可能导致合并冲突（可能甚至，因为我们已经更改了版本号）。如果是这样，请修复并提交。 现在我们已经完成了，并且可能会删除发布分支，因为我们不再需要它了： 12$ git branch -d release-1.2 删除了分支版本1.2（ff452fe）。 修补程序分支 可能来源于： master 必须合并回： develop 和 master 分支命名约定： hotfix-* 修补程序分支非常像发布分支，因为它们也是为了准备新的生产版本，尽管是计划外的。它们源于必须立即采取实际生产版本的不良状态。当必须立即解决生产版本中的严重错误时，可以从标记生产版本的主分支上的相应标记分支修补程序分支。 实质是团队成员（在develop分支机构）的工作可以继续，而另一个人正在准备快速生产修复。 创建修补程序分支从master分支创建修补程序 分支。例如，假设版本1.2是当前正在运行的生产版本，并且由于严重的错误而导致麻烦。但是变化develop仍然不稳定。然后我们可以分支修补程序分支并开始修复问题： 1234567$ git checkout -b hotfix-1.2.1 master 切换到新分支“hotfix-1.2.1” $ ./bump-version.sh 1.2.1 文件修改成功，版本提升到1.2.1。$ git commit -a -m “Bumped version number to 1.2.1” [hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1 1个文件改变了，1个插入（+），1个删除（ - ） 分支后不要忘记碰撞版本号！ 然后，修复错误并在一个或多个单独的提交中提交修复。 123$ git commit -m “修复了严重生产问题” [hotfix-1.2.1 abbe5d6]修复了严重生产问题5个文件发生了变化，32个插入（+），17个删除（ - ） 完成修补程序分支完成后，需要将错误修复合并回来master，但也需要合并回来develop，以保证错误修复程序也包含在下一个版本中。这与发布分支的完成方式完全相似。 首先，更新master并标记版本。 123456$ git checkout master 切换到分支&apos;master&apos; $ git merge --no-ff hotfix-1.2.1 由递归合并。（更改摘要）$ git tag -a 1.2.1 编辑：您可能还想使用-s或-u &lt;key&gt;标记以加密方式对您的标记进行签名。 接下来，也包括错误修复develop： 12345$ git checkout develop 切换到分支&apos;develop&apos; $ git merge --no-ff hotfix-1.2.1 由递归合并。（变更摘要） 此处规则的一个例外是， 当发布分支当前存在时，需要将修补程序更改合并到该发布分支中，而不是develop。在发布分支完成时，将错误修复反向合并到发布分支中最终会导致错误修复也被合并develop。（如果develop立即工作需要此错误修复并且不能等待发布分支完成，您可以安全地将错误修复合并到develop现在。） 最后，删除临时分支： 12$ git branch -d hotfix-1.2.1 删除了分支修补程序-12.2.1（是abbe5d6）。 摘要虽然这个分支模型并没有什么令人震惊的新功能，但这篇文章开头的“大图”数字在我们的项目中非常有用。它形成了一个易于理解的优雅心理模型，并允许团队成员形成对分支和发布过程的共同理解。","categories":[],"tags":[]},{"title":"SQL游标","slug":"SQL游标","date":"2019-05-14T08:41:22.000Z","updated":"2019-05-14T08:56:50.117Z","comments":true,"path":"2019/05/14/SQL游标/","link":"","permalink":"the-valley.github.io/2019/05/14/SQL游标/","excerpt":"","text":"SQL游标操作在阅读ShardingSphere文档的时候，提到了通过sql游标来进行结果归并。参考mysql官方文档，整理一下sql游标与procedure的用法。 定义procedure在procedure中使用sql游标来完成sum函数。12345678910111213141516171819202122# sql游标# 示例使用的是mysql官方的sakila数据库delimiter //create procedure cursor_payment_param(inout pament_result int) begin # 定义一个flag来标记是否完成 declare finished integer default false; declare per_amount int default 0; declare cursor_payment cursor for select amount from payment; declare continue handler for not found set finished = true; open cursor_payment; read_loop: LOOP fetch cursor_payment into per_amount; if finished then leave read_loop; end if; set pament_result = pament_result + per_amount; end loop; close cursor_payment; end;// # 结束标识 完善说明调用procedureprocedure和function类似，通过call关键字来调用。123set @pament_result = 0.0;call cursor_payment_param(@pament_result);select @pament_result; 查看procedure和function12show procedure status like 'cursor%';show function status like 'func_name'; 删除procedure1drop procedure if exists 'pament';","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"the-valley.github.io/tags/sql/"},{"name":"mysql","slug":"mysql","permalink":"the-valley.github.io/tags/mysql/"},{"name":"sql游标","slug":"sql游标","permalink":"the-valley.github.io/tags/sql游标/"}]},{"title":"springboot集成quartz实现定时任务调度","slug":"springboot集成quartz实现定时任务调度","date":"2019-05-05T03:25:40.000Z","updated":"2019-05-09T07:47:16.430Z","comments":true,"path":"2019/05/05/springboot集成quartz实现定时任务调度/","link":"","permalink":"the-valley.github.io/2019/05/05/springboot集成quartz实现定时任务调度/","excerpt":"在工作中需要写一个定时任务，在网上查阅了quartz任务调度框架相关资料，考虑到后期可能会有业务扩展所以决定用quartz来完成，在spirngboot 2以后可以直接通过starter的方式来引入。pom依赖如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt; quartz的主要组件 Jobdetail包含具体的任务信息 Trigger任务的触发器 Schedule具体的调度机制 SimpleScheduleBuilder简单任务调度 CronScheduleBuilder基于Crontab规则的任务调度","text":"在工作中需要写一个定时任务，在网上查阅了quartz任务调度框架相关资料，考虑到后期可能会有业务扩展所以决定用quartz来完成，在spirngboot 2以后可以直接通过starter的方式来引入。pom依赖如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt; quartz的主要组件 Jobdetail包含具体的任务信息 Trigger任务的触发器 Schedule具体的调度机制 SimpleScheduleBuilder简单任务调度 CronScheduleBuilder基于Crontab规则的任务调度 定义Jobdetail123JobDetail jobDetail = JobBuilder.newJob().withIdentity(new JobKey(jobName, JOB_DEFAULT_GROUP_NAME)) .ofType((Class&lt;Job&gt;) Class.forName(jobClass)) .build(); 定义调度规则简单任务调度，其中interval是指作业执行的时间间隔。下面的代码是以时间间隔为interval（单位：秒）的重复执行的调度规则。 1SimpleScheduleBuilder.repeatSecondlyForever(interval) crontab任务调度，其中cronExp是crontab表达式。 1CronScheduleBuilder.cronSchedule(cronExp) 定义好调度规则后，就可以定义触发器了。 定义触发器12345Trigger trigger = TriggerBuilder.newTrigger() .forJob(jobDetail) .withSchedule(SimpleScheduleBuilder.repeatSecondlyForever(interval)) .withIdentity(new TriggerKey(jobName, TRIGGER_DEFAULT_GROUP_NAME)) .build(); 添加作业到调度器12@Resourceprivate Scheduler scheduler; 12scheduler.scheduleJob(jobDetail, trigger);scheduler.start(); 为了方便作业的修改，定义一个作业的管理类，此类被定义为单例类，实现了对作业的添加，修改调度规则，作业的删除等。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190import com.aden.bern.leak.detection.job.AbstractJob;import lombok.extern.slf4j.Slf4j;import org.quartz.*;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.annotation.Scope;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.util.Map;/** * @author wangyong * @description */@Component@Scope(\"singleton\")@Slf4jpublic class QuartzManager implements ApplicationContextAware &#123; /** * 默认的作业组名称 */ private static final String JOB_DEFAULT_GROUP_NAME = \"JOB_GROUP\"; /** * 默认的触发器组名称 */ private static final String TRIGGER_DEFAULT_GROUP_NAME = \"JOB_GROUP\"; private ApplicationContext applicationContext; @Resource private Scheduler scheduler; @Resource private AutowiringSpringBeanJobFactory autowiringSpringBeanJobFactory; /** * 初始化 */ public void init() &#123; //启动所有任务 try &#123; scheduler.setJobFactory(autowiringSpringBeanJobFactory); //启动所有任务,这里获取AbstractTask的所有子类,继承的关系，取得所有子任务 Map&lt;String, AbstractJob&gt; tasks = applicationContext.getBeansOfType(AbstractJob.class); tasks.forEach((k, v) -&gt; &#123; Integer interval = v.getInterval();// String cronExp = v.getCronExpression(); if (interval != null) &#123; addJob(k, v.getClass().getName(), interval); &#125;// if (cronExp != null) &#123;// addJob(k, v.getClass().getName(), cronExp);// &#125; &#125;); log.info(\"Total jobs: &#123;&#125;，start jobs finished.\", tasks.size()); &#125; catch (SchedulerException e) &#123; log.error(e.getMessage(), e); throw new RuntimeException(\"init Scheduler failed\"); &#125; &#125; /** * 添加间隔性调度作业 * * @param jobName * @param jobClass * @param interval * @return */ public boolean addJob(String jobName, String jobClass, Integer interval) &#123; boolean result = false; try &#123; JobDetail jobDetail = JobBuilder.newJob().withIdentity(new JobKey(jobName, JOB_DEFAULT_GROUP_NAME)) .ofType((Class&lt;Job&gt;) Class.forName(jobClass)) .build(); Trigger trigger = TriggerBuilder.newTrigger() .forJob(jobDetail) .withSchedule(SimpleScheduleBuilder.repeatSecondlyForever(interval)) .withIdentity(new TriggerKey(jobName, TRIGGER_DEFAULT_GROUP_NAME)) .build(); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); result = true; &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); log.error(\"QuartzManager add job failed\"); &#125; return result; &#125; /** * 添加cron调度作业 * * @param jobName * @param jobClass * @param cronExp * @return */ public boolean addJob(String jobName, String jobClass, String cronExp) &#123; boolean result = false; if (!CronExpression.isValidExpression(cronExp)) &#123; log.error(\"Illegal cron expression format(&#123;&#125;)\", cronExp); return result; &#125; try &#123; JobDetail jobDetail = JobBuilder.newJob().withIdentity(new JobKey(jobName, JOB_DEFAULT_GROUP_NAME)) .ofType((Class&lt;Job&gt;) Class.forName(jobClass)) .build(); Trigger trigger = TriggerBuilder.newTrigger() .forJob(jobDetail) .withSchedule(CronScheduleBuilder.cronSchedule(cronExp)) .withIdentity(new TriggerKey(jobName, TRIGGER_DEFAULT_GROUP_NAME)) .build(); scheduler.scheduleJob(jobDetail, trigger); scheduler.start(); result = true; &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); log.error(\"QuartzManager add job failed\"); &#125; return result; &#125; /** * 更新作业 * * @param jobName * @param cronExp * @return */ public boolean updateJob(String jobName, String cronExp) &#123; boolean result = false; if (!CronExpression.isValidExpression(cronExp)) &#123; log.error(\"Illegal cron expression format(&#123;&#125;)\", cronExp); return result; &#125; JobKey jobKey = new JobKey(jobName, JOB_DEFAULT_GROUP_NAME); TriggerKey triggerKey = new TriggerKey(jobName, TRIGGER_DEFAULT_GROUP_NAME); try &#123; if (scheduler.checkExists(jobKey) &amp;&amp; scheduler.checkExists(triggerKey)) &#123; JobDetail jobDetail = scheduler.getJobDetail(jobKey); Trigger newTrigger = TriggerBuilder.newTrigger() .forJob(jobDetail) .withSchedule(CronScheduleBuilder.cronSchedule(cronExp)) .withIdentity(new TriggerKey(jobName, TRIGGER_DEFAULT_GROUP_NAME)) .build(); scheduler.rescheduleJob(triggerKey, newTrigger); result = true; &#125; else &#123; log.error(\"update job name:&#123;&#125;,group name:&#123;&#125; or trigger name:&#123;&#125;,group name:&#123;&#125; not exists..\", jobKey.getName(), jobKey.getGroup(), triggerKey.getName(), triggerKey.getGroup()); &#125; &#125; catch (SchedulerException e) &#123; log.error(e.getMessage(), e); log.error(\"update job name:&#123;&#125;,group name:&#123;&#125; failed!\", jobKey.getName(), jobKey.getGroup()); &#125; return result; &#125; /** * 删除作业 * * @param jobName * @return */ public boolean deleteJob(String jobName) &#123; boolean result = false; JobKey jobKey = new JobKey(jobName, JOB_DEFAULT_GROUP_NAME); try &#123; if (scheduler.checkExists(jobKey)) &#123; result = scheduler.deleteJob(jobKey); &#125; else &#123; log.error(\"delete job name:&#123;&#125;,group name:&#123;&#125; not exists.\", jobKey.getName(), jobKey.getGroup()); &#125; &#125; catch (SchedulerException e) &#123; log.error(e.getMessage(), e); log.error(\"delete job name:&#123;&#125;,group name:&#123;&#125; failed!\", jobKey.getName(), jobKey.getGroup()); &#125; return result; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; init()方法是调度器的初始化方法，作用是在springboot启动的时候去加载所有作业的实例（即继承了AbstractJob抽象类 的子类，在下文中会描述此抽象类），并启动调度器scheduler。 实现具体的作业逻辑为了实现springboot在启动的时候加载所有的调度作业，首先定义一个抽象父类： 123456789101112131415161718192021222324import org.springframework.scheduling.quartz.QuartzJobBean;/** * @author wangyong * @description 所有具体的任务都需要继承此类 */public abstract class AbstractJob extends QuartzJobBean &#123; /** * crontab表达式 */ protected String cronExpression; /** * 任务时间间隔，单位：秒 */ protected Integer interval; public String getCronExpression() &#123; return cronExpression; &#125; public Integer getInterval() &#123; return interval; &#125;&#125; 所有的作业实例都需要继承这个父类，springboot在启动时候会加载所有此抽象类实现的作业实例。下面代码是一个简单的示例作业： 12345678910111213141516171819202122import lombok.extern.slf4j.Slf4j;import org.quartz.DisallowConcurrentExecution;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.springframework.stereotype.Component;/** * @author wangyong * @description 示例作业 */@Slf4j@Component@DisallowConcurrentExecutionpublic class SampleJob extends AbstractJob &#123; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; /* 在这个方法中完成需要的业务逻辑 */ System.out.println(\"作业调度！！！\"); &#125;&#125; 注意：作业的默认调度规则是每间隔规定的时间会启动一个线程去执行整个作业，但是如果不希望作业叠加执行，需要在具体的作业实例上添加@DisallowConcurrentExecution注解，这样就有当前次作业执行结束后才会开始下一次的执行。 与springboot整合这一部分使用spring中的事件监听器来初始化加载，实现了spring中的ApplicationListener接口中的onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent)方法。具体代码如下： 12345678910111213141516171819202122232425262728import lombok.extern.slf4j.Slf4j;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextRefreshedEvent;import org.springframework.stereotype.Component;import javax.annotation.Resource;/** * @author wangyong * @description */@Component@Slf4jpublic class ApplicationStartQuartzJobListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Resource private QuartzManager quartzManager; @Override public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) &#123; try &#123; quartzManager.init(); log.info(\"调度任务启动成功！\"); &#125; catch (Exception e) &#123; log.error(\"调度任务启动失败，&#123;&#125;\", e.getMessage()); &#125; &#125;&#125; 定义作业工厂，来获取Spring上下文然后在创建Job时让Job自动注入到Spring容器中： 1234567891011121314151617181920212223242526272829import org.quartz.spi.TriggerFiredBundle;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.scheduling.quartz.SpringBeanJobFactory;import org.springframework.stereotype.Component;/** * @author wangyong * @description */@Componentpublic class AutowiringSpringBeanJobFactory extends SpringBeanJobFactory implements ApplicationContextAware &#123; private transient AutowireCapableBeanFactory beanFactory; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; final Object jobInstance = super.createJobInstance(bundle); beanFactory.autowireBean(jobInstance); return jobInstance; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.beanFactory = applicationContext.getAutowireCapableBeanFactory(); &#125;&#125; 在后续的业务迭代中，有新的作业需要只需要继承AbstractJob类，在executeInternal()方法中实现相应的作业逻辑就可以了。","categories":[],"tags":[{"name":"springboot","slug":"springboot","permalink":"the-valley.github.io/tags/springboot/"},{"name":"quartz","slug":"quartz","permalink":"the-valley.github.io/tags/quartz/"}]},{"title":"用java反射实现自定义规则对象属性拷贝","slug":"用java反射实现自定义规则对象属性拷贝","date":"2019-05-04T12:57:15.000Z","updated":"2019-05-05T10:04:45.682Z","comments":true,"path":"2019/05/04/用java反射实现自定义规则对象属性拷贝/","link":"","permalink":"the-valley.github.io/2019/05/04/用java反射实现自定义规则对象属性拷贝/","excerpt":"在工作中用到了protobuf，需要由protobuf类转成pojo，由于字段比较多，两个对象之间属性名不完全相同但是又存在一些映射规则，自己写了一个根据反射完成两个对象之间对应属性的赋值。直接上父抽象类代码：","text":"在工作中用到了protobuf，需要由protobuf类转成pojo，由于字段比较多，两个对象之间属性名不完全相同但是又存在一些映射规则，自己写了一个根据反射完成两个对象之间对应属性的赋值。直接上父抽象类代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161import com.wy.exception.ConvertException;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeanUtils;import java.beans.PropertyDescriptor;import java.lang.reflect.*;import java.util.Objects;/** * @author wangyong * @description pb对象与普通对象的转换 * @date 2019-04-10 */@Slf4jpublic abstract class AbstractConverter&lt;T, S&gt; &#123; private Class&lt;T&gt; targetClass; /** * 父类的构造函数，实例化一个目标类对象 */ public AbstractConverter() &#123; Type genericSuperClass = this.getClass().getGenericSuperclass(); //noinspection unchecked targetClass = ((Class&lt;T&gt;) ((ParameterizedType) genericSuperClass).getActualTypeArguments()[0]); &#125; /** * 执行转换 * * @param sourceObject 源对象 * @return */ public T convert(S sourceObject) &#123; T targetObject = newTargetClassInstance(); if (Objects.isNull(targetObject)) &#123; return null; &#125; PropertyDescriptor[] propertyDescriptors = BeanUtils.getPropertyDescriptors(targetObject.getClass()); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) &#123; copyValue(sourceObject, targetObject, propertyDescriptor); &#125; return targetObject; &#125; /** * 属性赋值 * * @param sourceObject 源对象 * @param targetObject 目标对象 * @param targetPropertyDescriptor 目标对象属性描述 */ protected void copyValue(S sourceObject, T targetObject, PropertyDescriptor targetPropertyDescriptor) &#123; String targetPropertyName = targetPropertyDescriptor.getName(); //获取源类的与目标类当前属性对应的名称 String sourcePropertyName = mappingProperty(targetPropertyName); PropertyDescriptor sourcePropertyDescriptor = BeanUtils .getPropertyDescriptor(sourceObject.getClass(), sourcePropertyName); if (Objects.isNull(sourcePropertyDescriptor)) &#123; log.debug(\"source class &#123;&#125; has no property &#123;&#125;.\", sourceObject.getClass(), sourcePropertyName); return; &#125; beforSetProperty(sourcePropertyDescriptor, sourceObject); setProperty(sourceObject, targetObject, targetPropertyDescriptor, sourcePropertyDescriptor); &#125; /** * 对目标对象属性赋值 * * @param sourceObject 源对象 * @param targetObject 目标对象 * @param targetPropertyDescriptor 目标对象属性描述 * @param sourcePropertyDescriptor 源对象属性描述 */ protected void setProperty(S sourceObject, T targetObject, PropertyDescriptor targetPropertyDescriptor, PropertyDescriptor sourcePropertyDescriptor) &#123; //读取源对象属性 //得到源对象中当前属性的get方法 Method sourceReadMethod = sourcePropertyDescriptor.getReadMethod(); //得到目标对象中的对应属性的set方法 Method targetWriteMethod = targetPropertyDescriptor.getWriteMethod(); if (Objects.isNull(targetWriteMethod)) &#123; log.debug(\"can not get write method of &#123;&#125; in class &#123;&#125;\", targetPropertyDescriptor.getName(), targetObject.getClass()); return; &#125; try &#123; if (Objects.isNull(sourceReadMethod.invoke(sourceObject))) &#123; return; &#125; setAccess(targetWriteMethod).invoke(targetObject, sourceReadMethod.invoke(sourceObject)); &#125; catch (IllegalAccessException | InvocationTargetException e) &#123; log.error(\"target class\" + targetObject.getClass().getName() + \" source class \" + sourceObject.getClass().getName() + \" target property \" + targetPropertyDescriptor.getName() + \" source property \" + sourcePropertyDescriptor.getName() + \" 赋值失败！\", e); &#125; &#125; /** * 如果方法的访问权限不为public，则修改为可以访问 * * @param method * @return */ private Method setAccess(Method method) &#123; if (!Modifier.isPublic(method.getModifiers())) &#123; method.setAccessible(true); &#125; return method; &#125; /** * 当构造函数的访问权限为私有时设置为可以访问 * * @param constructor * @return */ private Constructor setAccess(Constructor constructor) &#123; if (!Modifier.isPublic(constructor.getModifiers())) &#123; constructor.setAccessible(true); &#125; return constructor; &#125; /** * 对目标对象赋值前做的预处理 * * @param sourcePropertyDescriptor * @param sourceObject */ private void beforSetProperty(PropertyDescriptor sourcePropertyDescriptor, S sourceObject) &#123; &#125; /** * 具体字段名字的对应规则，默认不转换，子类可重写来实现新的对应规则 * * @param targetPropertyName 目标类的属性名称 * @return */ public String mappingProperty(String targetPropertyName) &#123; return targetPropertyName; &#125; /** * 实例化一个目标类属性 * * @return */ protected T newTargetClassInstance() &#123; try &#123; return targetClass.newInstance(); &#125; catch (InstantiationException | IllegalAccessException e) &#123; log.error(\"new instance of \" + targetClass.getName() + \" exception; \", e); return null; &#125; &#125;&#125; 泛型T为目标类型（比如pojo）S为源类型（比如PB类）。 实现自定义的字段映射规则子类通过重写此抽象类的mappingProperty(String targetPropertyName)方法来实现相应的属性映射规则。比如，当目标类的属性命名规则是源类的属性首字母小写时： 12345678910/** * 重写父类的字段映射规则，首字母小写 * * @param targetPropertyName 目标类的属性名称 * @return */ @Override public String mappingProperty(String targetPropertyName) &#123; return targetPropertyName.substring(0, 1).toLowerCase() + targetPropertyName.substring(1); &#125; 获取pb类的实例在使用protobuf类作为目标类时，需要使用pb类的builer来获取目标类的一个实例。因此在子类中需要重写父类的newTargetClassInstance()方法： 123456789/** * 当目标类为pb类时，重写父类的创建目标类实例的方法 * * @return */ @Override protected TargetClass.Builder newTargetClassInstance() &#123; return TargetClass.newBuilder(); &#125; 考虑到java反射的性能问题，在对程序性能要求比较高的场景中并不适合。","categories":[],"tags":[{"name":"java反射","slug":"java反射","permalink":"the-valley.github.io/tags/java反射/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-03-18T09:07:33.951Z","updated":"2019-03-18T09:07:33.951Z","comments":true,"path":"2019/03/18/hello-world/","link":"","permalink":"the-valley.github.io/2019/03/18/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}